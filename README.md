# 杂谈
## 辗转相除法
要想解释辗转相除法的原理，需要先知道以下两点：
一、一个一般定理：
    如果a是任一整数而b是任一大于零的整数，则我们总能找到一整数q，使
                     a=bq+r
    这里r是满足不等式0<=r<b的一个整数。

二、最大公因子的表示方法：
    如果整数a和b的最大公因子是d，则表示为d=(a,b)  

    给定a和b（a>=b)两个整数，求最大公因子d。
    根据上边给的定理，可以将a写成
    a=bq+r
    辗转相除法是告诉我们
    (a,b)=(b,r)
    即a和b的最大公因数和b和r（r是a除以b的余数）的最大公因数是相等的。

原理：因为对任意同时整除a和b的数u，有

      a=su，b=tu，
      它也能整除r，因为r=a-bq=su-qtu=(s-qt)u。
      反过来每一个整除b和r的整数v，有
      b=s'v , r=t'v
      它也能整除a，因为a=bq+r=s'vq+t'v=(s'q+t')v.
      因此a和b的每一个公因子同时也是b和r的一个公因子，反之亦然。这样由于a和b的全体公因子集合与b和r的全体公因子集合相同，所以a和b的最大公因子必须等于b和r的最大公因子，这就证明了上边的等式。即(a,b)=(b,r)。
      
## Introduction to data structure
### 线性结构
线性结构是最简单的数据结构，包括数组、链表，以及由它们衍生出来的栈、队列、哈希表。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196073863-67dd00c2-67b7-4b81-be08-b85c10ef0bae.png" width="600">
</div>

### 树
树是相对复杂的数据结构，其中比较有代表性的是二叉树，由它又衍生出了二叉堆之类的数据结构。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196073872-e4931893-ec3c-4e95-9768-82c006165ee1.png" width="300">
</div>

### 图
图是更为复杂的数据结构，因为在图中会呈现出多对多的关联关系

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196073895-96964919-f6cf-455b-bb97-639f70d19967.png" width="300">
</div>

### 其他数据结构
除上述所列的几种基本数据结构以外，还有一些其他的千奇百怪的数据结构。它们由基本数据结构变形而来，用于解决某些特定问题，如跳表、哈希链表、位图等。

## 关于算法的好坏
### 渐进时间复杂度（asymptotic time complexity）
设T(n)为程序基本操作执行次数的函数（也可以认为是程序的相对执行时间函数），n为输入规模，程序中最常见的4种执行方式分别是：
* T(n) = 3n，执行次数是线性的
* T(n) = 5logn，执行次数是用对数计算的
* T(n) = 2，执行次数是常量
* T(n) = 0.5n^2 + 0.5n，执行次数是用多项式计算的

若存在函数f(n)，使得当n趋近于无穷大时，T(n)/f(n)的**极限值**为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=O(f(n))，称为O(f(n))，O为算法的渐进时间复杂度，简称为时间复杂度。

因为渐进时间复杂度用大写O来表示，所以也被称为大O表示法。如：
* T(n) = O(n)
* T(n) = O(logn)
* T(n) = O(1)
* T(n) = =O(n^2)
不难得出以下结论：

$$
\mathrm{O}(1)<\mathrm{O}(\log n)<\mathrm{O}(\mathrm{n})<\mathrm{O}\left(\mathrm{n}^2\right)
$$

还有很多其他的时间复杂度： $\mathrm{O}(\mathrm{nlogn}) 、 \mathrm{O}\left(\mathrm{n}^3\right) 、 \mathrm{O}(\mathrm{mn}) 、 \mathrm{O}\left(2^{\mathrm{n}}\right) 、 \mathrm{O}(\mathrm{n} !)$

### 空间复杂度
和时间复杂度类似，空间复杂度是对一个算法在运行过程中临时占用存储空间大小的量度，它同样使用了大O表示法。

程序占用空间大小的计算公式记作S(n)=O(f(n))，其中n为问题的规模，f(n)为算法所占存储空间的函数

#### 常量空间
当算法的存储空间大小固定，和输入规模没有直接的关系时，空间复杂度记作O(1)。

#### 线性空间
当算法分配的空间是一个线性的集合（如数组），并且集合大小和输入规模n成正比时，空间复杂度记作O(n)。

#### 二维空间
当算法分配的空间是一个二维数组集合，并且集合的长度和宽度都与输入规模n成正比时，空间复杂度记作O(n2)。

#### 递归空间
递归是一个比较特殊的场景。虽然递归代码中并没有显式地声明变量或集合，但是计算机在执行程序时，会专门分配一块内存，用来存储“方法调用栈”。

“方法调用栈”包括进栈和出栈两个行为。当进入一个新方法时，执行入栈操作，把调用的方法和参数信息压入栈中。当方法返回时，执行出栈操作，把调用的方法和参数信息从栈中弹出。

由上面“方法调用栈”的出入栈过程可以看出，**执行递归操作所需要的内存空间和递归的深度成正比**。纯粹的递归操作的空间复杂度也是线性的，如果递归的深度是n，那么空间复杂度就是O(n)。

### 如何取舍
时间换空间还是vice versa？

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196113598-025e7b71-2bdc-4682-af61-6a1e0e712f32.png" width="1500">
</div>

# 数据结构基础
## 数组
数组对应的英文是array，是有限个相同类型的变量所组成的有序集合，数组中的每一个变量被称为元素。数组是最为简单、最为常用的数据结构。

数组的另一个特点，是在内存中顺序存储，因此可以很好地实现逻辑上的顺序表。

* 数组读取元素和更新元素的时间复杂度都是O(1)
* 数组扩容的时间复杂度是O(n)，插入并移动元素的时间复杂度也是O(n)，综合起来插入操作的时间复杂度是O(n)。
* 删除操作，只涉及元素的移动，时间复杂度也是O(n)。

### 数组的优劣势
优势：数组拥有非常高效的随机访问能力，只要给出下标，就可以用常量时间找到对应元素。有一种高效查找元素的算法叫作二分查找，就是利用了数组的这个优势。

劣势：数组的劣势，体现在插入和删除元素方面。由于数组元素连续紧密地存储在内存中，插入、删除元素都会导致大量元素被迫移动，影响效率。

总的来说，数组所适合的是读操作多、写操作少的场景，而链表则恰恰相反

## 链表
链表（linked list）是一种在物理上非连续、非顺序的数据结构，由若干节点（node）所组成。

单向链表的每一个节点又包含两部分，一部分是存放数据的变量data，另一部分是指向下一个节点的指针next。

双向链表比单向链表稍微复杂一些，它的每一个节点除了拥有data和next指针，还拥有指向前置节点的prev指针。

这正如地下党的联络方式，一级一级，单线传递。
### 内存储存方式
如果说数组在内存中的存储方式是顺序存储，那么链表在内存中的存储方式则是随机存储。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196078719-87590c47-d65b-4fb3-99c2-6490fb700c31.png" width="600">
</div>

### 基本操作
**查找节点**：在查找元素时，链表不像数组那样可以通过下标快速进行定位，只能从头节点开始向后一个一个节点逐一查找。链表中的数据只能按顺序进行访问，最坏的时间复杂度是O(n)。
**更新节点**：如果不考虑查找节点的过程，链表的更新过程会像数组那样简单，直接把旧数据替换成新数据即可

## 数组 VS 链表

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196079089-7e25e149-698b-4a7f-938f-6dbc4c025d7a.png" width="600">
</div>

从表格可以看出，数组的优势在于能够快速定位元素，对于读操作多、写操作少的场景来说，用数组更合适一些。

相反地，链表的优势在于能够灵活地进行插入和删除操作，如果需要在尾部频繁插入、删除元素，用链表更合适一些。

## 栈和队列
逻辑结构是抽象的概念，它依赖于物理结构而存在。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196079429-9715da93-7ebc-4f8b-85a7-beaf93279bec.png" width="500">
</div>

两个常用数据结构：栈和队列。这两者都属于逻辑结构，它们的物理实现既可以利用数组，也可以利用链表来完成。

### 栈 stack
栈（stack）是一种线性数据结构，栈中的元素只能先入后出（First In Last Out，简称FILO）。最早进入的元素存放的位置叫作栈底（bottom），最后进入的元素存放的位置叫作栈顶（top）。栈这种数据结构既可以用数组来实现，也可以用链表来实现。
#### 栈的基本操作
入栈 push：把新元素放入栈中，只允许从栈顶一侧放入元素，新元素的位置将会成为新的栈顶。以数组为例：
![image](https://user-images.githubusercontent.com/111955215/196079971-818060ec-a5e6-4fae-859b-25df593d7c1c.png)

出栈 pop：把元素从栈中弹出，只有栈顶元素才允许出栈，出栈元素的前一个元素将会成为新的栈顶。
![image](https://user-images.githubusercontent.com/111955215/196079983-0b401802-39b2-4bb6-9469-1c12730746d1.png)

入栈和出栈只会影响到最后一个元素，不涉及其他元素的整体移动，所以无论是以数组还是以链表实现，入栈、出栈的时间复杂度都是O(1)。

### 队列
队列（queue）是一种线性数据结构，它的特征和行驶车辆的单行隧道很相似。不同于栈的先入后出，队列中的元素只能先入先出（First In First Out，简称FIFO）。队列的出口端叫作队头（front），队列的入口端叫作队尾（rear）

与栈类似，队列这种数据结构既可以用数组来实现，也可以用链表来实现。
#### 队列的基本操作
入队（enqueue）：把新元素放入队列中，只允许在队尾的位置放入元素，新元素的下一个位置将会成为新的队尾。
出队操作（dequeue）：把元素移出队列，只允许在队头一侧移出元素，出队元素的后一个元素将会成为新的队头。

如果像这样不断出队，队头左边的空间失去作用，那队列的容量岂不是越来越小了？

用数组实现的队列可以采用**循环队列**的方式来维持队列容量的恒定

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196080588-67375ce5-c024-458a-8638-80c2db0d4cad.png" width="600">
</div>

### 栈与队列的应用
栈的输出顺序和输入顺序相反，所以栈通常用于对“历史”的回溯，也就是逆流而上追溯“历史”。
* 例如实现递归的逻辑，就可以用栈来代替，因为栈可以回溯方法的调用链。
* 栈还有一个著名的应用场景是面包屑导航，使用户在浏览页面时可以轻松地回溯到上一级或更上一级页面。

队列的输出顺序和输入顺序相同，所以队列通常用于对“历史”的回放，也就是按照“历史”顺序，把“历史”重演一遍。
* 例如在多线程中，争夺公平锁的等待队列，就是按照访问顺序来决定线程在队列中的次序的。
* 再如网络爬虫实现网站抓取时，也是把待抓取的网站URL存入队列中，再按照存入队列的顺序来依次抓取和解析的。

## 散列表
散列表也叫作哈希表（hash table），这种数据结构提供了键（Key）和值（Value）的映射关系。只要给出一个Key，就可以高效查找到它所匹配的Value，时间复杂度接近于O(1)。
![image](https://user-images.githubusercontent.com/111955215/196081186-8b7bf856-26ca-4254-95c2-eb68985258a5.png)

散列表在本质上也是一个数组；可以说是数组和链表的结合

数组只能根据下标，像a[0]、a[1]、a[2]、a[3]、a[4]这样来访问，而散列表的Key则是以字符串类型为主的。

而哈希函数可以通过某种方式，把Key和数组下标进行转换
### 哈希函数
在Java及大多数面向对象的语言中，每一个对象都有属于自己的hashcode，这个hashcode是区分不同对象的重要标识。无论对象自身的类型是什么，它们的hashcode都是一个整型变量。

通过哈希函数，我们可以把字符串或其他类型的Key，转化成数组的下标index。

#### 写操作（put）
如调用hashMap.put("002931", "王五")，意思是插入一组Key为002931、Value为王五的键值对。

但是，由于数组的长度是有限的，当插入的Entry越来越多时，不同的Key通过哈希函数获得的下标有可能是相同的。例如002936这个Key对应的数组下标是2；002947这个Key对应的数组下标也是2。这种情况，就叫作哈希冲突。如何解决？

##### 开放寻址法

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196088166-768dab94-8a6f-4fcf-ad20-42e2a0068ebd.png" width="600">
</div>

##### 链表法
HashMap数组的每一个元素不仅是一个Entry对象，还是一个链表的头节点（数组的每一个元素都与一个链表对应）。每一个Entry对象通过next指针指向它的下一个Entry节点。当新来的Entry映射到与之冲突的数组位置时，只需要插入到对应的链表中即可。

HashMap数组的每一个元素不仅是一个Entry对象，还是一个链表的头节点。每一个Entry对象通过next指针指向它的下一个Entry节点。当新来的Entry映射到与之冲突的数组位置时，只需要插入到对应的链表中即可。
![image](https://user-images.githubusercontent.com/111955215/196088516-3f9c86e0-4f9d-4668-84f7-35b9a7cfbc3c.png)

#### 读操作（get）
调用 hashMap.get("002936")，意思是查找Key为002936的Entry在散列表中所对应的值。

具体该怎么做呢？下面以链表法为例来讲一下。

第1步，通过哈希函数，把Key转化成数组下标2。

第2步，找到数组下标2所对应的元素，如果这个元素的Key是002936，那么就找到了；如果这个Key不是002936也没关系，由于数组的每个元素都与一个链表对应，我们可以顺着链表慢慢往下找，看看能否找到与Key相匹配的节点。

#### 扩容（resize）
当经过多次元素插入，散列表达到一定饱和度时，Key映射位置发生冲突的概率会逐渐提高。这样一来，大量元素拥挤在相同的数组下标位置，形成很长的链表，对后续插入操作和查询操作的性能都有很大影响。这时，散列表就需要扩展它的长度，也就是进行扩容。
![image](https://user-images.githubusercontent.com/111955215/196088661-a6a3f897-ce2f-41b0-919f-a6e63c1f41df.png)
步骤：
1．扩容，创建一个新的Entry空数组，长度是原数组的2倍。

2．重新Hash，遍历原Entry数组，把所有的Entry重新Hash到新数组中。为什么要重新Hash呢？因为长度扩大以后，Hash的规则也随之改变。
经过扩容，原本拥挤的散列表重新变得稀疏，原有的Entry也重新得到了尽可能均匀的分配。
![image](https://user-images.githubusercontent.com/111955215/196088811-361d50a2-c780-4ee7-abab-a7c594242b1b.png)

# 树
## 树的简介
有许多逻辑关系并不是简单的线性关系，在实际场景中，常常存在着一对多，甚至是多对多的情况。其中树和图就是典型的非线性数据结构

在数据结构中，树的定义如下。
树（tree）是n（n≥0）个节点的有限集。当n=0时，称为空树。在任意一个非空树中，有如下特点。
* 有且仅有一个特定的称为根的节点。
* 当n>1时，其余节点可分为m（m>0）个互不相交的有限集，每一个集合本身又是一个树，并称为根的子树。
![image](https://user-images.githubusercontent.com/111955215/196089307-c524df74-2e57-4124-91a2-0780313e4171.png)

在上图中，节点1是根节点（root）；节点5、6、7、8是树的末端，没有“孩子”，被称为叶子节点（leaf）。图中的虚线部分，是根节点1的其中一个子树。
![image](https://user-images.githubusercontent.com/111955215/196089394-497d7df7-91d6-44dc-96bb-700f289bbcb3.png)

在上图中，节点4的上一级节点，是节点4的父节点（parent）；从节点4衍生出来的节点，是节点4的孩子节点（child）；和节点4同级，由同一个父节点衍生出来的节点，是节点4的兄弟节点（sibling）。
树的最大层级数，被称为树的高度或深度。显然，上图这个树的高度是4。

## 二叉树
二叉树节点的两个孩子节点，一个被称为左孩子（left child），一个被称为右孩子（right child）。这两个孩子节点的顺序是固定的，就像人的左手就是左手，右手就是右手，不能够颠倒或混淆。
![image](https://user-images.githubusercontent.com/111955215/196089522-0b6720bc-0748-4cd6-8384-cdd43b31f8d4.png)

### 满二叉树
一个二叉树的所有非叶子节点都存在左右孩子，并且所有叶子节点都在同一层级上，那么这个树就是满二叉树。
![image](https://user-images.githubusercontent.com/111955215/196089604-3a004814-d742-4073-9be1-10379e33d31d.png)

### 完全二叉树
对一个有n个节点的二叉树，按层级顺序编号，则所有节点的编号为从1到n。如果这个树所有节点和同样深度的满二叉树的编号为从1到n的节点位置相同，则这个二叉树为完全二叉树。

![image](https://user-images.githubusercontent.com/111955215/196089778-09009af0-5ccb-47c1-8efa-f5501b2d3a3a.png)

完全二叉树的条件没有满二叉树那么苛刻：满二叉树要求所有分支都是满的；而完全二叉树只需保证最后一个节点之前的节点都齐全即可

### 二叉树的物理存储结构
#### 链式存储结构。
相较于链表，二叉树稍微复杂一些，一个节点最多可以指向左右两个孩子节点，所以二叉树的每一个节点包含3部分
* 存储数据的data变量
* 指向左孩子的left指针
* 指向右孩子的right指针
![image](https://user-images.githubusercontent.com/111955215/196089950-fe4777f0-beab-4081-b500-297abbf9ad47.png)

#### 数组。
使用数组存储时，会按照层级顺序把二叉树的节点放到数组中对应的位置上。如果某一个节点的左孩子或右孩子空缺，则数组的相应位置也空出来。这样可以更方便地**在数组中定位二叉树的孩子节点和父节点**。

**假设一个父节点的下标是parent，那么它的左孩子节点下标就是2×parent + 1；右孩子节点下标就是2×parent + 2。**

![image](https://user-images.githubusercontent.com/111955215/196089993-a8b1e5eb-b5bf-45eb-a634-459acbc5c56b.png)

### 二叉树的应用
#### 查找
二叉查找树（binary searchtree）在二叉树的基础上增加了以下几个条件。
* 如果左子树不为空，则左子树上所有节点的值均小于根节点的值
* 如果右子树不为空，则右子树上所有节点的值均大于根节点的值
* 左、右子树也都是二叉查找树

![image](https://user-images.githubusercontent.com/111955215/196090419-e0290aa5-5577-4ac9-9326-0396560536d4.png)

对于一个节点分布相对均衡的二叉查找树来说，如果节点总数是n，那么搜索节点的**时间复杂度就是O(logn)**，**和树的深度**是一样的。这种依靠比较大小来逐步查找的方式，和二分查找算法非常相似。
#### 维持相对顺序
二叉查找树还有另一个名字——二叉排序树（binary sort tree）。

新插入的节点，同样要遵循二叉排序树的原则。例如插入新元素5，由于5<6，5>3，5>4，所以5最终会插入到节点4的右孩子位置。

![image](https://user-images.githubusercontent.com/111955215/196090649-96b4059d-644c-428e-93dc-24833e3dc93f.png)

这一切看起来很顺利，然而却隐藏着一个致命的问题。什么问题呢？下面请试着在二叉查找树中依次插入9、8、7、6、5、4，看看会出现什么结果。

![image](https://user-images.githubusercontent.com/111955215/196090711-918b7472-fe0f-4d3e-9813-ba63ec9570fb.png)

不只是外观看起来变得怪异了，查询节点的时间复杂度也退化成了O(n)，如何解决？————二叉树的自平衡（红黑树、AVL树、树堆）

### 二叉树的遍历
在计算机程序中，遍历本身是一个线性操作。所以遍历同样具有线性结构的数组或链表，是一件轻而易举的事情。

反观二叉树，是典型的非线性数据结构，遍历时需要把非线性关联的节点转化成一个线性的序列，以不同的方式来遍历，遍历出的序列顺序也不同。

从节点之间位置关系的角度来看，二叉树的遍历分为4种。
1. 前序遍历。
2. 中序遍历。
3. 后序遍历。
4. 层序遍历。

从更宏观的角度来看，二叉树的遍历归结为两大类。
1. 深度优先遍历（前序遍历、中序遍历、后序遍历）。
2. 广度优先遍历（层序遍历）。

#### 深度优先遍历
所谓深度优先，顾名思义，就是偏向于纵深，“一头扎到底”的访问方式。

二叉树用递归方式来实现前序、中序、后序遍历，是最为自然的方式。这3种遍历方式的区别，仅仅是输出的执行位置不同：前序遍历的
输出在前，中序遍历的输出在中间，后序遍历的输出在最后。

代码中值得注意的一点是二叉树的构建。二叉树的构建方法有很多，这里把一个线性的链表转化成非线性的二叉树，链表节点的顺序恰恰是二叉树前序遍历的顺序。链表中的空值，代表二叉树节点的左孩子或右孩子为空的情况。

##### 前序遍历
二叉树的前序遍历，输出顺序是根节点、左子树、右子树。

![image](https://user-images.githubusercontent.com/111955215/196096266-0f1c5c45-b772-437c-b75d-2b606cfd58f5.png)

##### 中序遍历
二叉树的中序遍历，输出顺序是左子树、根节点、右子树

找完子树的左中右，则将其视为左，再往上找
##### 后序遍历

#### 广度优先遍历

## 二叉堆
二叉堆是实现堆排序及优先队列的基础

二叉堆本质上是一种完全二叉树，它分为两个类型。
1. 最大堆：最大堆的任何一个父节点的值，都大于或等于它左、右孩子节点的值。![image](https://user-images.githubusercontent.com/111955215/196097546-19f00f46-7d5e-4e81-96d1-d245cf31e6d8.png)

2. 最小堆：最小堆的任何一个父节点的值，都小于或等于它左、右孩子节点的值。![image](https://user-images.githubusercontent.com/111955215/196097561-b17bb439-1f50-4790-b32c-e25d0d096175.png)

二叉堆的根节点叫作堆顶。

最大堆和最小堆的特点决定了：最大堆的堆顶是整个堆中的最大元素；最小堆的堆顶是整个堆中的最小元素。

### 二叉堆的自我调整
对于二叉堆，有如下几种操作。
1. 插入节点。
2. 删除节点。
3. 构建二叉堆。

#### 插入节点

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196098021-f742b0a7-4e9d-4185-9f36-e0ce254e409c.png" width="1200">
</div>

#### 删除节点
二叉堆删除节点的过程和插入节点的过程正好相反，所删除的是处于堆顶的节点。例如删除最小堆的堆顶节点1。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196098307-1649dba8-a3dd-404b-bf05-dcd27b08775d.png" width="1200">
</div>

其实插入和删除都是通过逐个比较来实现的

#### 构建二叉堆
构建二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质就是让所有非叶子节点依次“下沉”。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196098881-c3e5344f-44d4-40ac-9516-4276417f722e.png" width="1200">
</div>

堆的插入操作是单一节点的“上浮”，堆的删除操作是单一节点的“下沉”，这两个操作的平均交换次数都是堆高度的一半，所以时间复杂度是O(logn)。但构建堆的时间复杂度却并不是O(nlogn)，而是O(n)。这涉及数学推导过程。

## 优先队列
队列的特点是先进先出（FIFO），优先队列不再遵循先入先出的原则，而是分为两种情况。
* 最大优先队列，无论入队顺序如何，都是当前最大的元素优先出队
* 最小优先队列，无论入队顺序如何，都是当前最小的元素优先出队
例如有一个最大优先队列，其中的最大元素是8，那么虽然8并不是队头元素，但出队时仍然让元素8首先出队

![image](https://user-images.githubusercontent.com/111955215/196106462-b2fe2a8b-ad56-4425-9dbf-3b153960596e.png)

要实现以上需求，利用线性数据结构并非不能实现，但是时间复杂度较高。

而最大堆和最小堆分别可以实现提取最大值和最小值的需求：每一次出队操作就是删除堆顶节点。

二叉堆节点“上浮”和“下沉”的时间复杂度都是O(logn)，所以优先队列入队和出队的时间复杂度也是O(logn)

# 排序算法
根据时间复杂度的不同，主流的排序算法可以分为3大类。

一、 时间复杂度为 $O\left(n^2\right)$ 的排序算法
* 冒泡排序
* 选择排序
* 插入排序
* 希尔排序（希尔排序比较特殊, 它的性能略优于 $\mathrm{O}\left(\mathrm{n}^2\right)$, 但又比不上 O(nlogn), 姑且把它归入本类)

二、 时间复杂度为 $O(n \log n)$ 的排序算法
* 快速排序
* 归并排序
* 堆排序

三、 时间复杂度为线性的排序算法
 * 计数排序
 * 桶排序
 * 基数排序
 
 ![image](https://user-images.githubusercontent.com/111955215/196330090-a8f84cea-8c8f-4ebb-bcd2-aff6dc54fa2d.png)

 ## 冒泡排序
把相邻的元素两两比较，当一个元素大于右侧相邻元素时，交换它们的位置；当一个元素小于或等于右侧相邻元素时，位置不变。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196108365-d73777d2-1f29-4a95-9932-1b2a81b428fe.png" width="1200">
</div>

冒泡排序是一种稳定排序, 值相等的元素并不会打乱原本的顺序。 由于该排序算法的每一轮都要遍历所有元素, 总共遍历（元素数量-1） 轮, 所以平均时间复杂度是 $\mathrm{O}\left(\mathrm{n}^2\right)$ 。

### 冒泡排序的优化
![image](https://user-images.githubusercontent.com/111955215/196108945-2fd540c9-114c-4d1c-b088-a7f5bee6bb39.png)


**优化一**  如上图：如果在本轮排序中，元素有交换，则说明数列无序；如果没有元素交换，则说明数列已然有序，然后直接跳出大循环。

![image](https://user-images.githubusercontent.com/111955215/196108985-fd23f888-f87d-4215-94e1-215a35114353.png)

这个数列的特点是前半部分的元素（3、4、2、1）无序，后半部分的元素（5、6、7、8）按升序排列，并且后半部分元素中的最小值也大于前半部分元素的最大值。这样的话，其实右面的许多元素已经是有序的了，可是每一轮还是白白地比较了许多次。这个问题的关键点在于对数列有序区的界定。按照现有的逻辑，有序区的长度和排序的轮数是相等的。实际上，数列真正的有序区可能会大于这个长度，如上述例子中在第2轮排序时，后面的5个元素实际上都已经属于有序区了。因此后面的多次元素比较是没有意义的。

**优化二**  可以在每一轮排序后，记录下来最后一次元素交换的位置，该位置即为无序数列的边界，再往后就是有序区了。

**优化三：鸡尾酒排序**  
冒泡排序的每一个元素都可以像小气泡一样，根据自身大小，一点一点地向着数组的一侧移动。算法的每一轮都是从左到右来比较元素，进行**单向**的位置交换的。

而鸡尾酒排序的元素比较和交换过程是**双向**的。

<div align=center>
<img src="https://user-images.githubusercontent.com/111955215/196109794-e80688f1-03f4-437c-9321-858f7716d7be.png" width="1200">
</div>

鸡尾酒排序也可以和之前所的2个优化方法结合使用

鸡尾酒排序的优点是能够在特定条件下，减少排序的回合数；而缺点也很明显，就是代码量几乎增加了1倍。它能发挥出优势的场景，是大部分元素已经有序的情况

## 快速排序
同冒泡排序一样，快速排序也属于交换排序，通过元素之间的比较和交换位置来达到排序的目的。不同的是，冒泡排序在每一轮中只把1个元素冒泡到数列的一端，而快速排序则在每一轮挑选一个基准元素，并让其他比它大的元素移动到数列一边，比它小的元素移动到数列的另一边，从而把数列拆解成两个部分。

![image](https://user-images.githubusercontent.com/111955215/196110452-5d2cf7ce-862f-4fc2-adc2-aecd8704fc56.png)

假如给出一个8个元素的数列, 一般情况下, 使用冒泡排序需要比 较 7 轮, 每一轮把 1 个元素移动到数列的一端, 时间复杂度是 $\mathrm{O}\left(\mathrm{n}^2\right)$ 。

而快速排序如下：

![image](https://user-images.githubusercontent.com/111955215/196110547-bde5b361-2024-47e2-b454-17dfa6b4f474.png)

每一轮的比较和交换, 需要把数组全部元素都遍历一遍, 时间复杂 度是 $\mathrm{O}(\mathrm{n})$ 。这样的遍历一共需要多少轮呢? 假如元素个数是 $\mathrm{n}$, 那么平 均情况下需要logn轮, 因此快速排序算法总体的平均时间复杂度 是 $O(n \log n)$ 。

### 基准元素的选择
那么如何选择基准元素呢？最简单的方式是选择数列的第1个元素。这种选择在绝大多数情况下是没有问题的。但是，假如有一个原本逆序的数列，期望排序成顺序数列，那么会出现什么情况呢？在这种极端情况下, 快速排序需要进 行 $n$ 轮, 时间复杂度退化成了 $O\left(n^2\right)$ 。所以，虽然快速排序的平均时间复杂度是 $\mathrm{O}(\mathrm{nlogn})$,但最坏情况下 的时间复杂度是 $\mathrm{O}\left(\mathrm{n}^2\right)$ 。

### 双边循环法
其实就是交换将左右指针放置在合理的位置，然后交换左右指针的位置以实现排序
![image](https://user-images.githubusercontent.com/111955215/196327229-3723de98-5fbe-4d1e-8d84-3c9fb38e136d.png)

### 单边循环法
其实和双边循环法差不多
![image](https://user-images.githubusercontent.com/111955215/196327538-0be81a5e-678c-4eb5-aa03-002f46d2c3fa.png)

## 堆排序
由于二叉堆的这个特性，每一次删除旧堆顶，调整后的新堆顶都是大小仅次于旧堆顶的节点。那么只要反复删除堆顶，反复调整二叉堆，所得到的集合就会成为一个有序集合

由此，可以归纳出堆排序算法的步骤：
1. 把无序数组构建成二叉堆。需要从小到大排序，则构建成最大堆；需要从大到小排序，则构建成最小堆。
2. 循环删除堆顶元素，替换到二叉堆的末尾，调整堆产生新的堆顶

堆排序的空间复杂度是O(1)，因为并没有开辟额外的集合空间。

二叉堆的节点“**下沉**”调整（downAdjust 方法）是堆排序算法的基础，这个调节操作本身的时间复杂度是O(logn)，而把无序数组构建成二叉堆，这一步的时间复杂度是O(n)，两个步骤是并列关系，所以整体的时间复杂度是O(nlogn)。

快速排序的最坏时间复杂度是 $\mathrm{O}\left(\mathrm{n}^2\right)$, 而堆排序的最坏时间复 杂度稳定在 $O(n l o g n) 。$

此外, 快速排序递归和非递归方法的 平均空间复杂度都是 $O(\log n$ ，而堆排序的空间复杂度是O(1)。

## 计数排序和桶排序
有一些特殊的排序并不基于元素比较，如计数排序、桶排序、基数排序。

### 计数排序
以计数排序来说，这种排序算法是利用数组下标来确定元素的正确位置的,见下例：假设数组中有20个随机整数，取值范围为0～10，要求用最快的速度把这20个整数从小到大进行排序。

考虑到这些整数只能够在0、1、2、3、4、5、6、7、8、9、10这11个数中取值，取值范围有限。所以，可以根据这有限的范围，建立一个长度为11的数组。数组下标从0到10，元素初始值全为0。

![image](https://user-images.githubusercontent.com/111955215/196328766-14f5a827-8186-41bd-8600-596d6dd62955.png)

假设20个随机整数的值为：9，3，5，4，9，1，2，7，8，1，3，6，5，3，4，0，10，9 ，7，9
下面就开始遍历这个无序的随机数列，每一个整数按照其值对号入座，同时，对应数组下标的元素进行加1操作。最终，当数列遍历完毕时，数组的状态如下。

![image](https://user-images.githubusercontent.com/111955215/196328823-556883e5-d436-470e-9093-0754289bb0a4.png)

有了这个统计结果，排序就很简单了。直接遍历数组，输出数组元素的下标值，元素的值是几，就输出几次：0，1，1，2，3，3，3，4，4，5，5，6，7，7，8，9，9，9，9，10

这就是计数排序的基本过程，它适用于一定范围内的整数排序。**在取值范围不是很大**的情况下，它的性能甚至快过那些时间复杂度为O(nlogn)的排序。

#### 优化
只以数列的最大值来决定统计数组的长度，其实并不严谨。例如下面的数列：95，94，91，98，99，90，99，93，91，92。如果创建长度为100的数组，那么前面从0到89的空间位置就都浪费了。

解决：只要不再以输入数列的最大值+1作为统计数组的长度，而是以数列最大值-最小值+1作为统计数组的长度即可

计数排序有它的局限性，主要表现为如下两点。
1. 当数列最大和最小值差距过大时，并不适合用计数排序。例如给出20个随机整数，范围在0到1亿之间，这时如果使用计数排序，需要创建长度为1亿的数组。不但严重浪费空间，而且时间复杂度也会随之升高。
2. 当数列元素不是整数时，也不适合用计数排序。如果数列中的元素都是小数，如25.213，或0.00 000 001这样的数字，则无法创建对应的统计数组。这样显然无法进行计数排序。

### 桶排序
桶排序同样是一种线性时间的排序算法。类似于计数排序所创建的统计数组，桶排序需要创建若干个桶来协助排序。

每一个桶（bucket）代表一个区间范围，里面可以承载一个或多个元素。

假设有一个非整数数列如下：4.5，0.84，3.25，2.18，0.5

桶排序的第1步，就是创建这些桶，并确定每一个桶的区间范围。区间跨度 = （最大值-最小值）/ （桶的数量 - 1）

![image](https://user-images.githubusercontent.com/111955215/196329849-8cae0d55-cdcc-46e9-97a5-194e27c23fae.png)

第2步，遍历原始数列，把元素对号入座放入各个桶中。

第3步，对每个桶内部的元素分别进行排序（显然，只有第1个桶需要排序）。

第4步，遍历所有的桶，输出所有元素。

桶排序的时间复杂度有些复杂：第1步，求数列最大、最小值，运算量为n。第2步，创建空桶，运算量为n。第3步，把原始数列的元素分配到各个桶中，运算量为n。第4步，在每个桶内部做排序，在元素分布相对均匀的情况下，所有桶的运算量之和为n。第5步，输出排序数列，运算量为n。因此，桶排序的总体时间复杂度为O(n)。空间复杂度同样是O(n)。

桶排序的性能并非绝对稳定。如果元素的分布极不均衡，在极端情况下，第一个桶中有n-1个元素，最后一个桶中有1个元素。此时的时间复杂度将退化为O(nlogn)，而且还白白创建了许多空桶。
